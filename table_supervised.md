# テーブルデータを用いた教師あり学習のアルゴリズム

**万能なアルゴリズムはない！**

L1正則化
L2正則化

## 線形モデル

### 線形回帰
### ロジスティック回帰



## 決定木ベース
### 決定木

### ランダムフォレスト
沢山の小さな決定木をつくり組み合わせる
データと特徴量をランダムにサンプリング
多数決や平均をとることで、個々の木の予測の不安定さを打ち消し、安定した予測を得る。
並列的学習
各モデルは独立

### 勾配ブースティング
沢山の小さな決定木をつくり組み合わせる
新しいモデルは、前のモデルの予測と実際の値との残差(損失関数の勾配)を予測するように学習
各モデルの結果を足し合わせる
逐次的学習
各モデルは依存
XGBoostやLightGBMがある
LightGBMはXGBoostからさらに高速化・省メモリ化を目指した実装。
LightGBMはOptunaでハイパーパラメータのチューニングが簡単にできる




近年の多くのデータ分析コンペティション（Kaggleなど）や実務において、テーブルデータに対しては、XGBoostやLightGBMといった勾配ブースティング系のアルゴリズムが非常に高い性能を発揮するケースが圧倒的に多いです。ランダムフォレストも依然として強力です。

XGBoost/LightGBM/ランダムフォレストは、比較的デフォルトに近いパラメータでもある程度の性能が出やすく、チューニングの勘所も広く知られています。


テーブルデータの分析スキルを効率的に習得するという観点では、まず線形モデル、決定木、そしてその発展形であるランダムフォレストや勾配ブースティング（XGBoost/LightGBM）を優先的に学ぶのが最も費用対効果が高いと言えます。

## その他
### 優先度2
Naive Bayes (ナイーブベイズ)
k-NN

### 優先度3
サポートベクターマシン (SVM)
ニューラルネットワーク




